# LlamaController User Manual

## 1. Introduction

LlamaController is a web-based management system for controlling the lifecycle of llama.cpp models. It provides centralized model management, Ollama API compatibility, secure access, and multi-GPU support. This manual guides users through installation, configuration, usage, API integration, advanced features, troubleshooting, and testing best practices.

### Key Features

- Centralized management for multiple llama.cpp models
- Ollama-compatible REST API for seamless integration
- Secure authentication and token-based access
- Multi-GPU selection and process management
- User-friendly Web UI for model operations

### Target Audience

- AI/ML engineers
- DevOps teams
- Application developers
- Researchers

### Manual Structure

1. Introduction
2. Installation & Setup
3. Basic Usage
4. API Reference
5. Multi-GPU Features
6. Web UI Guide
7. Troubleshooting
8. Testing Best Practices

---
